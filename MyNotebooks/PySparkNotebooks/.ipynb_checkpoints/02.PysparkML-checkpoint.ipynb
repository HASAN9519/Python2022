{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-2SB3EEFG:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1eea581a380>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"Practice\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, age: int, Experience: int, Salary: int]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark = spark.read.csv(r'C:\\Users\\SHEHA\\Downloads\\GitHubRepository\\SampleDatasets\\test1.csv',header=True,inferSchema=True)\n",
    "dfspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     Jack| 27|         5| 17000|\n",
      "|    Karim| 35|         7| 22000|\n",
      "|     Mick| 20|         6| 13000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new independent feature with column age and Experience using VectorAssembler module\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler = VectorAssembler(inputCols=[\"age\",\"Experience\"],outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+--------------------+\n",
      "|     Name|age|Experience|Salary|Independent Features|\n",
      "+---------+---+----------+------+--------------------+\n",
      "|    Krish| 31|        10| 30000|         [31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000|          [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000|          [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000|          [23.0,2.0]|\n",
      "|     Jack| 27|         5| 17000|          [27.0,5.0]|\n",
      "|    Karim| 35|         7| 22000|          [35.0,7.0]|\n",
      "|     Mick| 20|         6| 13000|          [20.0,6.0]|\n",
      "+---------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output=featureassembler.transform(dfspark)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "|          [27.0,5.0]| 17000|\n",
      "|          [35.0,7.0]| 22000|\n",
      "|          [20.0,6.0]| 13000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"Salary\")\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "# train test split\n",
    "train_data,test_data = finalized_data.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|          [20.0,6.0]| 13000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [35.0,7.0]| 22000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [27.0,5.0]| 17000|\n",
      "|         [31.0,10.0]| 30000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(featuresCol='Independent Features', labelCol='Salary')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([612.2575, 118.109])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2159.3778872806065"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intercepts\n",
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|Independent Features|Salary|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|          [24.0,3.0]| 20000|17207.884200800738|\n",
      "|          [27.0,5.0]| 17000|19280.874653526334|\n",
      "|         [31.0,10.0]| 30000| 22320.44964582693|\n",
      "+--------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "pred_results = regressor.evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4250.846935632889, 23991264.487838905)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[total_bill: double, tip: double, sex: string, smoker: string, day: string, time: string, size: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with tips dataset\n",
    "df = spark.read.csv(r'C:\\Users\\SHEHA\\Downloads\\GitHubRepository\\SampleDatasets\\tips.csv',header=True,inferSchema=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Categorical Features\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"sex\",outputCol=\"sex_indexed\")\n",
    "df_r = indexer.fit(df).transform(df)\n",
    "df_r.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|smoker_indexed|day_indexed|time_index|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|       0.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|       0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|       0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|       0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|       0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Handling multiple Categorical Features\n",
    "indexer=StringIndexer(inputCols=[\"smoker\",\"day\",\"time\"],outputCols=[\"smoker_indexed\",\"day_indexed\",\"time_index\"])\n",
    "df_r=indexer.fit(df_r).transform(df_r)\n",
    "df_r.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=['tip','size','sex_indexed','smoker_indexed','day_indexed','time_index'],outputCol=\"Independent Features\")\n",
    "output=featureassembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Independent Features|\n",
      "+--------------------+\n",
      "|[1.01,2.0,1.0,0.0...|\n",
      "|[1.66,3.0,0.0,0.0...|\n",
      "|[3.5,3.0,0.0,0.0,...|\n",
      "|[3.31,2.0,0.0,0.0...|\n",
      "|[3.61,4.0,1.0,0.0...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('Independent Features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+--------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|smoker_indexed|day_indexed|time_index|Independent Features|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+--------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|           0.0|        1.0|       0.0|[1.01,2.0,1.0,0.0...|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|       0.0|[1.66,3.0,0.0,0.0...|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|           0.0|        1.0|       0.0|[3.5,3.0,0.0,0.0,...|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|           0.0|        1.0|       0.0|[3.31,2.0,0.0,0.0...|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|           0.0|        1.0|       0.0|[3.61,4.0,1.0,0.0...|\n",
      "+----------+----+------+------+---+------+----+-----------+--------------+-----------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|Independent Features|total_bill|\n",
      "+--------------------+----------+\n",
      "|[1.01,2.0,1.0,0.0...|     16.99|\n",
      "|[1.66,3.0,0.0,0.0...|     10.34|\n",
      "|[3.5,3.0,0.0,0.0,...|     21.01|\n",
      "|[3.31,2.0,0.0,0.0...|     23.68|\n",
      "|[3.61,4.0,1.0,0.0...|     24.59|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"total_bill\")\n",
    "finalized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data = finalized_data.randomSplit([0.75,0.25])\n",
    "regressor = LinearRegression(featuresCol='Independent Features', labelCol='total_bill')\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([2.9205, 4.0674, -1.4471, 2.754, -0.4516, -0.1291])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934485513167622"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|Independent Features|total_bill|        prediction|\n",
      "+--------------------+----------+------------------+\n",
      "|(6,[0,1],[1.25,2.0])|     10.07| 12.67879029485173|\n",
      "|(6,[0,1],[1.25,2.0])|     10.51| 12.67879029485173|\n",
      "|(6,[0,1],[2.34,4.0])|     17.81|23.996850968581263|\n",
      "| (6,[0,1],[2.5,4.0])|     18.35|24.464132038386698|\n",
      "|(6,[0,1],[2.64,3.0])|     17.59| 20.80564878162644|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final comparison\n",
    "pred_results.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47196705413679585, 4.2732245187013165, 30.909413406985074)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance Metrics\n",
    "pred_results.r2,pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "bb65f437f2d19e9610fb47dbaf617190e7fd17f6b40db81a2233836212cf96da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
