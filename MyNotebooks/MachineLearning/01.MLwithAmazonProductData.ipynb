{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffac949",
   "metadata": {},
   "source": [
    "### Importing Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31a2826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85c557",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02849383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Da Silva takes the divine by storm with this unique new novel.  She develops a world unlike any others while keeping it firmly in the real world.  This is a very well written and entertaining novel.  I was quite impressed and intrigued by the way that this solid storyline was developed, bringing the readers right into the world of the story.  I was engaged throughout and definitely enjoyed my time spent reading it.I loved the character development in this novel.  Da Silva creates a cast of high school students who actually act like high school students.  I really appreciated the fact that none of them were thrown into situations far beyond their years, nor did they deal with events as if they had decades of life experience under their belts.  It was very refreshing and added to the realism and impact of the novel.  The friendships between the characters in this novel were also truly touching.Overall, this novel was fantastic.  I can&#8217;t wait to read more and to find out what happens next in the series.  I&#8217;d definitely recommend this debut novel by Da Silva to those who want a little YA fun with a completely unique & shocking storyline.Please note that I received a complimentary copy of this work in exchange for an honest review.\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "file_name = 'Datafiles/booksreview.json'\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append((review['reviewText'], review['overall']))\n",
    "print(reviews[0][0])\n",
    "print(reviews[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c93e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code\n",
    "# creating class to load data\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68c80d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love the book, great story line, keeps you entertained.for a first novel from this author she did a great job,  Would definitely recommend!\n",
      "4.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# main code\n",
    "file_name = 'Datafiles/booksreview.json'\n",
    "Reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        Reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "print(Reviews[5].text)\n",
    "print(Reviews[5].score)\n",
    "print(Reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4741f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d6ab0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf25af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(Reviews, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0aab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670\n",
      "330\n",
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n"
     ]
    }
   ],
   "source": [
    "print(len(training))\n",
    "print(len(test))\n",
    "print(training[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81d2817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "POSITIVE\n",
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# test code\n",
    "train_x = [x.text for x in training]\n",
    "train_y = [x.sentiment for x in training]\n",
    "\n",
    "test_x = [x.text for x in test]\n",
    "test_y = [x.sentiment for x in test]\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])\n",
    "print(test_x[0])\n",
    "print(test_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67c59d",
   "metadata": {},
   "source": [
    "### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "824e4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vivid characters and descriptions. The author has created a tale that grabs your attention and I couldn't put it down.\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "  (0, 7086)\t1\n",
      "  (0, 1148)\t1\n",
      "  (0, 350)\t2\n",
      "  (0, 1800)\t1\n",
      "  (0, 6595)\t1\n",
      "  (0, 562)\t1\n",
      "  (0, 3054)\t1\n",
      "  (0, 1558)\t1\n",
      "  (0, 6475)\t1\n",
      "  (0, 6593)\t1\n",
      "  (0, 2895)\t1\n",
      "  (0, 7353)\t1\n",
      "  (0, 539)\t1\n",
      "  (0, 1515)\t1\n",
      "  (0, 5197)\t1\n",
      "  (0, 3545)\t1\n",
      "  (0, 2007)\t1\n"
     ]
    }
   ],
   "source": [
    "# converting text to numerical vectors, bag of words(bow)\n",
    "# https://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)  # first fit then transform\n",
    "test_x_vectors = vectorizer.transform(test_x)    # not used fit as it won't be used on training model\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "print(train_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1de508",
   "metadata": {},
   "source": [
    "## Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2f417",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee5dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every new Myke Cole book is better than the last, and this is no exception. If you haven't read the Shadow Ops series before start with Control Point, but go ahead and order Fortress Frontier and Breach Zone as well - you're going to want them.\n",
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "# predicting on test set\n",
    "print(test_x[0])\n",
    "print(test_y[0])\n",
    "clf_svm.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a6fde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "# predicting on test set\n",
    "print(test_y[0])\n",
    "clf_dec.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dca0bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# train_x_vectors is a sparse matrix, dense data is required to work with GaussianNB\n",
    "# Using train_x_vectors.toarray() to convert to a dense numpy array\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.toarray(), train_y)\n",
    "# predicting on test set\n",
    "print(test_y[0])\n",
    "clf_gnb.predict(test_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36ddfe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "# predicting on test set\n",
    "print(test_y[0])\n",
    "clf_log.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a7207",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f7f2166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.7666666666666667\n",
      "0.8121212121212121\n",
      "0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "print(clf_gnb.score(test_x_vectors.toarray(), test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a48ea970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91319444 0.21052632 0.22222222]\n",
      "[0.87260035 0.1        0.        ]\n",
      "[0.89678511 0.08510638 0.09090909]\n",
      "[0.91370558 0.12244898 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_dec.predict(test_x_vectors), average=None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_gnb.predict(test_x_vectors.toarray()), average=None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))\n",
    "print(f1_score(test_y, clf_log.predict(test_x_vectors), average=None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66453deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d86fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
