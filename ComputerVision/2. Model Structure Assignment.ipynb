{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6e3c2a",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#q1)-Explain-the-parameter-count-in-the-batchnorm-layer\" data-toc-modified-id=\"q1)-Explain-the-parameter-count-in-the-batchnorm-layer-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>q1) Explain the parameter count in the batchnorm layer</a></span></li><li><span><a href=\"#q2)-Activation-softmax-why-at-the-classification-layer?\" data-toc-modified-id=\"q2)-Activation-softmax-why-at-the-classification-layer?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>q2) Activation softmax why at the classification layer?</a></span></li><li><span><a href=\"#q3)-Build-a-Model-Structure\" data-toc-modified-id=\"q3)-Build-a-Model-Structure-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>q3) Build a Model Structure</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797ff315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-23T06:08:14.678842Z",
     "start_time": "2023-09-23T06:08:01.162676Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm, time\n",
    "\n",
    "import glob\n",
    "import random,time\n",
    "\n",
    "import math\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.regularizers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83208d4f",
   "metadata": {},
   "source": [
    "## q1) Explain the parameter count in the batchnorm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae2552a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-23T06:10:29.373732Z",
     "start_time": "2023-09-23T06:10:29.096277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 1)       28        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 8)       80        \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 12)      876       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 224, 224, 12)     48        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,032\n",
      "Trainable params: 1,008\n",
      "Non-trainable params: 24\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network with batchnorm layer\n",
    "filters1= 1\n",
    "filters2= 8\n",
    "filters3= 12\n",
    "krnl= 3\n",
    "dropout = 0.3\n",
    "\n",
    "dimn = 224\n",
    "inputs = Input(shape=(dimn, dimn, 3))\n",
    "\n",
    "y1 = Conv2D(filters=filters1, kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "y2 = Conv2D(filters=filters2, kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal', use_bias =True)(y1)\n",
    "y = Conv2D(filters=filters3, kernel_size=(krnl, krnl), activation='relu', padding='same', kernel_initializer='he_normal')(y2)\n",
    "y = BatchNormalization()(y)\n",
    "\n",
    "outputs = y\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142f2813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-23T06:10:44.213636Z",
     "start_time": "2023-09-23T06:10:44.184198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers weights 10\n"
     ]
    }
   ],
   "source": [
    "weights = model.get_weights()\n",
    "print('layers weights', len( weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c46d0c",
   "metadata": {},
   "source": [
    "<div>Answer\n",
    "    \n",
    "There are 4 parameters in batchnorm layer. They are [gamma weights, beta weights, moving_mean(non-trainable), moving_variance(non-trainable)], each having 12 elements (size of input layer). in order to make batch normalization work during training, need to keep track of distributions of each normalized dimensions. By default, they compute 4 parameters per feature on previous layer. Those parameters helps properly propagate and backpropagate information.\n",
    "\n",
    "So 4*12 = 48 parameters after batchnorm layer.\n",
    "\n",
    "here there is 3 hidden layer so for each hidden layer 2 weights will be add into model weights, for batchnorm layer 4 weight will be added\n",
    "\n",
    "so total layers weights = (3*2)+4 = 10</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b84512",
   "metadata": {},
   "source": [
    "## q2) Activation softmax why at the classification layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27e6ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-23T06:15:12.461320Z",
     "start_time": "2023-09-23T06:15:12.448111Z"
    }
   },
   "source": [
    "Answer\n",
    "\n",
    "softmax function is used as activation function in the output layer of neural network models that predict a multinomial probability distribution, That is softmax is used as the activation function for multi-class classification problems where class membership is required on more than two class labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.409px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
