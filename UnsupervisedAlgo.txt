###      DBSCAN clustering

# Advantages

1) Does not require deductive specification of number of clusters
2) Able to identify noise data while clustering
3) DBSCAN algorithm is able to find arbitrarily size and arbitrarily shaped clusters

# Disadvantages
1) DBSCAN algorithm fails in case of varying density clusters
2) Fails in case of neck type of dataset

###      k-Means clustering

# Advantages
## Relatively simple to implement
## Scales to large data sets
## Guarantees convergence
## Can warm-start positions of centroids
## Easily adapts to new examples
## Generalizes to clusters of different shapes and sizes such as elliptical clusters

# Disadvantages
## k-means has trouble clustering data where clusters are of varying sizes and density
## Centroids can be dragged by outliers or outliers might get their own cluster instead of being ignored
## As number of dimensions increases, a distance-based similarity measure converges to a constant value between any given examples

###      Hierarchical Clustering

# Advantages
## donâ€™t have to pre-specify any particular number of clusters
## Can obtain any desired number of clusters by cutting Dendrogram at proper level
## They may correspond to meaningful classification
## Easy to decide number of clusters by merely looking at Dendrogram

# Disadvantages
## Hierarchical Clustering does not work well on vast amounts of data
## All approaches to calculate similarity between clusters have their own disadvantages
## In hierarchical Clustering, once a decision is made to combine two clusters, it can not be undone
## Different measures have problems with one or more of following
### Sensitivity to noise and outliers
### Faces Difficulty when handling with different sizes of clusters
### It is breaking large clusters
### In this technique, order of data has an impact on final results