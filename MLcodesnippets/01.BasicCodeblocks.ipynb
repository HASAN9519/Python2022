{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07da13a8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-missing-value\" data-toc-modified-id=\"Removing-missing-value-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Removing missing value</a></span></li><li><span><a href=\"#preprocessing\" data-toc-modified-id=\"preprocessing-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#transform-column-to-datetime\" data-toc-modified-id=\"transform-column-to-datetime-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>transform column to datetime</a></span></li><li><span><a href=\"#column-droping\" data-toc-modified-id=\"column-droping-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>column droping</a></span></li><li><span><a href=\"#droping-rows\" data-toc-modified-id=\"droping-rows-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>droping rows</a></span></li><li><span><a href=\"#changing-all-columns\" data-toc-modified-id=\"changing-all-columns-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>changing all columns</a></span></li><li><span><a href=\"#get_dummies\" data-toc-modified-id=\"get_dummies-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>get_dummies</a></span></li><li><span><a href=\"#Merging-dataframes\" data-toc-modified-id=\"Merging-dataframes-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>Merging dataframes</a></span></li><li><span><a href=\"#str.replace()\" data-toc-modified-id=\"str.replace()-1.2.7\"><span class=\"toc-item-num\">1.2.7&nbsp;&nbsp;</span>str.replace()</a></span></li><li><span><a href=\"#str.split()\" data-toc-modified-id=\"str.split()-1.2.8\"><span class=\"toc-item-num\">1.2.8&nbsp;&nbsp;</span>str.split()</a></span></li><li><span><a href=\"#convert-column-type\" data-toc-modified-id=\"convert-column-type-1.2.9\"><span class=\"toc-item-num\">1.2.9&nbsp;&nbsp;</span>convert column type</a></span></li><li><span><a href=\"#Handling-categorical-feature-Using-Map-function\" data-toc-modified-id=\"Handling-categorical-feature-Using-Map-function-1.2.10\"><span class=\"toc-item-num\">1.2.10&nbsp;&nbsp;</span>Handling categorical feature Using Map function</a></span></li><li><span><a href=\"#LabelEncoder\" data-toc-modified-id=\"LabelEncoder-1.2.11\"><span class=\"toc-item-num\">1.2.11&nbsp;&nbsp;</span>LabelEncoder</a></span></li><li><span><a href=\"#index\" data-toc-modified-id=\"index-1.2.12\"><span class=\"toc-item-num\">1.2.12&nbsp;&nbsp;</span>index</a></span></li><li><span><a href=\"#Group-by\" data-toc-modified-id=\"Group-by-1.2.13\"><span class=\"toc-item-num\">1.2.13&nbsp;&nbsp;</span>Group by</a></span></li><li><span><a href=\"#binning\" data-toc-modified-id=\"binning-1.2.14\"><span class=\"toc-item-num\">1.2.14&nbsp;&nbsp;</span>binning</a></span></li><li><span><a href=\"#pivot\" data-toc-modified-id=\"pivot-1.2.15\"><span class=\"toc-item-num\">1.2.15&nbsp;&nbsp;</span>pivot</a></span></li><li><span><a href=\"#P-value\" data-toc-modified-id=\"P-value-1.2.16\"><span class=\"toc-item-num\">1.2.16&nbsp;&nbsp;</span>P-value</a></span></li><li><span><a href=\"#describe()-with-object-type-data\" data-toc-modified-id=\"describe()-with-object-type-data-1.2.17\"><span class=\"toc-item-num\">1.2.17&nbsp;&nbsp;</span>describe() with object type data</a></span></li><li><span><a href=\"#Using-lambda\" data-toc-modified-id=\"Using-lambda-1.2.18\"><span class=\"toc-item-num\">1.2.18&nbsp;&nbsp;</span>Using lambda</a></span></li><li><span><a href=\"#train-test-split\" data-toc-modified-id=\"train-test-split-1.2.19\"><span class=\"toc-item-num\">1.2.19&nbsp;&nbsp;</span>train test split</a></span></li></ul></li><li><span><a href=\"#Feature-Selection-Techniques\" data-toc-modified-id=\"Feature-Selection-Techniques-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Feature Selection Techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recursive-Feature-Elimination-(RFE)\" data-toc-modified-id=\"Recursive-Feature-Elimination-(RFE)-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Recursive Feature Elimination (RFE)</a></span></li><li><span><a href=\"#Mutual-Info-Regression\" data-toc-modified-id=\"Mutual-Info-Regression-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Mutual Info Regression</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Standardization-on-train-set-and-test-set\" data-toc-modified-id=\"Data-Standardization-on-train-set-and-test-set-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Data Standardization on train set and test set</a></span></li><li><span><a href=\"#Outlier-Detection-and-Removal-(optional)\" data-toc-modified-id=\"Outlier-Detection-and-Removal-(optional)-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Outlier Detection and Removal (optional)</a></span></li></ul></li></ul></li><li><span><a href=\"#Building-Model\" data-toc-modified-id=\"Building-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Building Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression-Model\" data-toc-modified-id=\"Multiple-Linear-Regression-Model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Multiple Linear Regression Model</a></span></li><li><span><a href=\"#K-Nearest-Neighbor(KNN)-Model\" data-toc-modified-id=\"K-Nearest-Neighbor(KNN)-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>K-Nearest Neighbor(KNN) Model</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation\" data-toc-modified-id=\"Model-Evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-Evaluation-on-train-and-test-dataset\" data-toc-modified-id=\"Model-Evaluation-on-train-and-test-dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Model Evaluation on train and test dataset</a></span></li><li><span><a href=\"#Model-with-Crossvalidation\" data-toc-modified-id=\"Model-with-Crossvalidation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Model with Crossvalidation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827787dd",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476711e0",
   "metadata": {},
   "source": [
    "## Removing missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd21cde",
   "metadata": {},
   "source": [
    "```\n",
    "# removing missing values\n",
    "data.dropna(axis = 0, how ='any',inplace=True) \n",
    "\n",
    "# checking missing value\n",
    "data.isnull().sum()\n",
    "\n",
    "cat_cols = data.select_dtypes('object').columns\n",
    "[features for features in df.columns if df[features].isnull().sum()>0]\n",
    "\n",
    "# using heatmap to see missing value\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n",
    "\n",
    "# Replace missing values with mode\n",
    "df['Product_Category_2'] = df['Product_Category_2'].fillna(df['Product_Category_2'].mode()[0])\n",
    "df['Product_Category_2'].isnull().sum()\n",
    "\n",
    "# counting missing data in each column in dataset with many columns\n",
    "missing_data = df.isnull()\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7abb",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a43374",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column Age\n",
    "df['Age']= label_encoder.fit_transform(df['Age'])\n",
    "df['Age'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad027e5b",
   "metadata": {},
   "source": [
    "### transform column to datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af450c",
   "metadata": {},
   "source": [
    "```\n",
    "import datetime\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f4b08",
   "metadata": {},
   "source": [
    "### column droping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ce521",
   "metadata": {},
   "source": [
    "```\n",
    "data = data.drop(\"datetime\", axis=1)\n",
    "data = data.drop([\"casual\",\"registered\"],axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e16395",
   "metadata": {},
   "source": [
    "### droping rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411afe72",
   "metadata": {},
   "source": [
    "```\n",
    "# droping all row with value ? \n",
    "df = df[(df != '?').all(axis=1)]\n",
    "df.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d29b3f",
   "metadata": {},
   "source": [
    "### changing all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87440016",
   "metadata": {},
   "source": [
    "```\n",
    "# changing column names\n",
    "df.columns = ['SL', 'SW', 'PL', 'PW', 'species']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20589b0",
   "metadata": {},
   "source": [
    "###  get_dummies\n",
    "method of Pandas is another way to create one-hot encoded features, creating dummy variable for all labels for all categorical column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a5f2a",
   "metadata": {},
   "source": [
    "```\n",
    "# creating dummy variable for all labels for all categorical column\n",
    "df = pd.get_dummies(df)\n",
    "df.head()\n",
    "\n",
    "# drop_first=True drops first categorical value\n",
    "df_city = pd.get_dummies(df['City_Category'],drop_first=True)\n",
    "\n",
    "final_df = pd.get_dummies(final_df, columns=[\"Airline\", \"Source\", \"Destination\",\"Additional_Info\"], drop_first = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483c377",
   "metadata": {},
   "source": [
    "### Merging dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254a089",
   "metadata": {},
   "source": [
    "```\n",
    "# how='left' works as sql left join and on='Country Code' is column based on two dataframes joining\n",
    "final_df = pd.merge(df, df_country, on='Country Code', how='left')\n",
    "final_df.shape\n",
    "\n",
    "# Merge both train and test data by row wise for Feature Engineering\n",
    "df = pd.concat([df_train, df_test],axis=0)\n",
    "df.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58d28b",
   "metadata": {},
   "source": [
    "### str.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7d8e6",
   "metadata": {},
   "source": [
    "```\n",
    "df['Stay_In_Current_City_Years']=df['Stay_In_Current_City_Years'].str.replace('+','',regex=False)\n",
    "df['Stay_In_Current_City_Years'].unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d263df6",
   "metadata": {},
   "source": [
    "### str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047001c8",
   "metadata": {},
   "source": [
    "```\n",
    "final_df['Date']=final_df['Date_of_Journey'].str.split('/').str[0]\n",
    "final_df['Month']=final_df['Date_of_Journey'].str.split('/').str[1]\n",
    "final_df['Year']=final_df['Date_of_Journey'].str.split('/').str[2]\n",
    "\n",
    "final_df['duration_hour']=final_df['Duration'].str.split(' ').str[0].str.split('h').str[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b2559",
   "metadata": {},
   "source": [
    "### convert column type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04154338",
   "metadata": {},
   "source": [
    "```\n",
    "# convert object into integers\n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].astype('int64')\n",
    "df.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd93601",
   "metadata": {},
   "source": [
    "### Handling categorical feature Using Map function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610cc04",
   "metadata": {},
   "source": [
    "```\n",
    "# Handling categorical feature Gender\n",
    "df['Gender']=df['Gender'].map({'M':0,'F':1})\n",
    "df.head()\n",
    "\n",
    "df['Age'].value_counts().sort_values()\n",
    "\n",
    "l = sorted(df['Age'].unique())\n",
    "df['Age'] = df['Age'].map({k:i+1 for i,k in enumerate(l)})\n",
    "\n",
    "df['Age'].value_counts().sort_values()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a5cf0",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2cb953",
   "metadata": {},
   "source": [
    "```\n",
    "# 'LabelEncoder' can be used to normalize labels\n",
    "# This transformer should be used to encode target values y and not input X\n",
    "ffrom sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df.species = encoder.fit_transform(df.species)\n",
    "\n",
    "# can see classes after fit or fit_transform of train data\n",
    "labelencoder.classes_\n",
    "\n",
    "# link: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc5066c",
   "metadata": {},
   "source": [
    "### index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02885ef",
   "metadata": {},
   "source": [
    "```\n",
    "country_names = final_df.Country.value_counts().index\n",
    "country_val=final_df.Country.value_counts().values\n",
    "\n",
    "# reset index after droping rows\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b174409",
   "metadata": {},
   "source": [
    "### Group by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446d44d",
   "metadata": {},
   "source": [
    "```\n",
    "ratings=final_df.groupby(['Aggregate rating','Rating color','Rating text']).size().reset_index().rename(columns={0:'Rating Count'})\n",
    "final_df[final_df['Rating color']=='White'].groupby('Country').size().reset_index()\n",
    "final_df.groupby(['Aggregate rating','Country']).size().reset_index().head(5)\n",
    "final_df[['Country','Currency']].groupby(['Country','Currency']).size().reset_index()\n",
    "\n",
    "# groupby function to find average \"price\" of each car based on \"body-style\"\n",
    "df[['price','body-style']].groupby(['body-style'],as_index= False).mean()\n",
    "\n",
    "grouped_test2 = df_gptest[['drive-wheels', 'price']].groupby(['drive-wheels'])\n",
    "# obtaining values of method group using method \"get_group\"\n",
    "grouped_test2.get_group('4wd')['price']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222e7a6",
   "metadata": {},
   "source": [
    "### binning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4715219",
   "metadata": {},
   "source": [
    "```\n",
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
    "group_names = ['Low', 'Medium', 'High']\n",
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d5724",
   "metadata": {},
   "source": [
    "### pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc4f25",
   "metadata": {},
   "source": [
    "```\n",
    "# grouped data is much easier to visualize when it is made into a pivot table \n",
    "# A pivot table is like an Excel spreadsheet with one variable along column\n",
    "# and another along row, can convert dataframe to a pivot table using method \"pivot\" to create a pivot table from groups\n",
    "df_gptest = df[['drive-wheels','body-style','price']]\n",
    "grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()\n",
    "grouped_pivot = grouped_test1.pivot(index='drive-wheels', columns='body-style')\n",
    "grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0\n",
    "grouped_pivot\n",
    "\n",
    "#use the grouped results\n",
    "plt.pcolor(grouped_pivot, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccd8ee",
   "metadata": {},
   "source": [
    "### P-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc79c9ab",
   "metadata": {},
   "source": [
    "```\n",
    "from scipy import stats\n",
    "pearson_coef, p_value = stats.pearsonr(df['wheel-base'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5d5a3",
   "metadata": {},
   "source": [
    "### describe() with object type data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed501d56",
   "metadata": {},
   "source": [
    "```\n",
    "df.describe(include=['object'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f013282",
   "metadata": {},
   "source": [
    "### Using lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca1f2f",
   "metadata": {},
   "source": [
    "```\n",
    "df[\"Date\"] = df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[0])\n",
    "df[\"Month\"] = df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[1])\n",
    "df[\"Year\"] = df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8a715",
   "metadata": {},
   "source": [
    "```\n",
    "df2['NormalizedAnnualCompensation'] = df2.apply(lambda x: x['CompTotal']*12 if x.CompFreq == 'Monthly'\n",
    "                                    else (x['CompTotal']*52 if x.CompFreq == 'Weekly' else  x['CompTotal']), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6723f1",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361f936f",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data.drop(columns=['SalePrice']), data['SalePrice'], test_size=0.2, random_state=33)\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)\n",
    "\n",
    "# split data\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y,random_state=33)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235e9ed",
   "metadata": {},
   "source": [
    "## Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485bb67",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcf620",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "rfe.fit(xtrain, ytrain)\n",
    "\n",
    "# zip() function returns a zip object which is an iterator of tuples where first item in each passed iterator is paired together \n",
    "# and then second item in each passed iterator are paired together etc\n",
    "# If passed iterators have different lengths, iterator with least items decides length of new iterator\n",
    "feature_list=[]\n",
    "for i, col in zip(range(xtrain.shape[1]), xtrain.columns):\n",
    "    print(i)\n",
    "    print(f\"{col} selected={rfe.support_[i]} rank={rfe.ranking_[i]}\")\n",
    "    if rfe.ranking_[i] == 1:\n",
    "        feature_list.append(col)\n",
    "feature_list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c29107",
   "metadata": {},
   "source": [
    "### Mutual Info Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7b0c29",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "scores = mutual_info_regression(xtrain[feature_list], ytrain, random_state=33)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.index = xtrain[feature_list].columns\n",
    "scores.sort_values(by=0, ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4ca81",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4913fe",
   "metadata": {},
   "source": [
    "### Data Standardization on train set and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f137c",
   "metadata": {},
   "source": [
    "```\n",
    "print(xtrain[feature_list].shape)\n",
    "print(xtest[feature_list].shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be280a6",
   "metadata": {},
   "source": [
    "```\n",
    "# Data Standardization on training and test data\n",
    "xtrain_scaled = xtrain[feature_list].copy()\n",
    "print(xtrain_scaled.shape)\n",
    "xtest_scaled = xtest[feature_list].copy()\n",
    "print(xtest_scaled.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38276396",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# fit and transform are both applied on training data\n",
    "xtrain_scaled[feature_list] = scaler.fit_transform(xtrain_scaled[feature_list])\n",
    "# only transform is applied on test data as features used to fit training data is applied in test data to perform transform \n",
    "xtest_scaled[feature_list] = scaler.transform(xtest_scaled[feature_list])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883eafbe",
   "metadata": {},
   "source": [
    "```\n",
    "sns.pairplot(xtrain_scaled)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359bc8c5",
   "metadata": {},
   "source": [
    "### Outlier Detection and Removal (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad5c1b",
   "metadata": {},
   "source": [
    "```\n",
    "newxtrain = xtrain_scaled.copy()\n",
    "newxtrain.shape\n",
    "newytrain = ytrain.copy()\n",
    "newytrain.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26485f",
   "metadata": {},
   "source": [
    "```\n",
    "# orginal function\n",
    "class OutlierTreatment:\n",
    "    \n",
    "    def __init__(self, dff):\n",
    "        self.dff = dff\n",
    "        \n",
    "    def getInfo(self):\n",
    "        return (self.dff.shape)\n",
    "    \n",
    "    def outlier(self):\n",
    "        Q1 = self.dff.quantile(0.25)\n",
    "        Q3 = self.dff.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5*IQR\n",
    "        upper_limit = Q3 + 1.5*IQR\n",
    "        return lower_limit, upper_limit\n",
    "        \n",
    "    def countoutlier(self, dfa):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        Total_outlier = len(dfa[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)])\n",
    "        return Total_outlier\n",
    "    \n",
    "    def cleanoutlier(self, dfa):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        dfx = dfa[(self.dff>self.lower_limit)&(self.dff<self.upper_limit)]\n",
    "        return dfx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1a875",
   "metadata": {},
   "source": [
    "```\n",
    "# modified function\n",
    "class OutlierTreatment:\n",
    "    \n",
    "    def __init__(self, dff):\n",
    "        self.dff = dff\n",
    "    \n",
    "    def outlier(self):\n",
    "        Q1 = self.dff.quantile(0.25)\n",
    "        Q3 = self.dff.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5*IQR\n",
    "        upper_limit = Q3 + 1.5*IQR\n",
    "        return lower_limit, upper_limit\n",
    "        \n",
    "    def countoutlier(self, dfx):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        Total_outlier = len(dfx[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)])\n",
    "        return Total_outlier\n",
    "    \n",
    "    def cleanoutlier(self, dfx, dfy):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        outliers = dfx[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)]\n",
    "        dfx.drop(outliers.index, inplace=True)\n",
    "        dfy.drop(outliers.index, inplace=True)\n",
    "        return dfx, dfy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63414e59",
   "metadata": {},
   "source": [
    "```\n",
    "# checking total outlier in every feature column\n",
    "for i in newxtrain.columns:\n",
    "        d = OutlierTreatment(newxtrain[i])\n",
    "        d.outlier()\n",
    "        print(i,' ',d.countoutlier(newxtrain))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb0832",
   "metadata": {},
   "source": [
    "```\n",
    "for i in newxtrain.columns:\n",
    "    d = OutlierTreatment(newxtrain[i])\n",
    "    if d.countoutlier(newxtrain) < 5:\n",
    "        d.cleanoutlier(newxtrain, newytrain)\n",
    "print(newxtrain.shape)\n",
    "print(newytrain.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0294e7e0",
   "metadata": {},
   "source": [
    "```\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.set(style='darkgrid')\n",
    "sns.boxplot(data=newxtrain)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8126070",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62a039",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924c69e",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "class Metrics:\n",
    "    def evaluate(self, model, features, target):\n",
    "        ypred = model.predict(features)\n",
    "        mae = mean_absolute_error(y_true=target, y_pred=ypred)\n",
    "        mse = mean_squared_error(y_true=target, y_pred=ypred)\n",
    "        r2 = r2_score(y_true=target, y_pred=ypred)*100\n",
    "        print(f\"MAE :: {mae: .4f}\")\n",
    "        print(f\"MSE :: {mse: .4f}\")\n",
    "        print(f\"R2 :: {r2: .4f}\")\n",
    "        return [np.round(mae, 4), np.round(mse, 4), np.round(r2, 4)]\n",
    "evaluator = Metrics()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa94628d",
   "metadata": {},
   "source": [
    "```\n",
    "Linearmodel = LinearRegression()\n",
    "Linearmodel.fit(newxtrain, newytrain)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a1476",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor(KNN) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83712b17",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knnmodel = KNeighborsRegressor(n_neighbors=7)\n",
    "knnmodel.fit(newxtrain, newytrain)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0b014",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0504a",
   "metadata": {},
   "source": [
    "## Model Evaluation on train and test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38509cf0",
   "metadata": {},
   "source": [
    "Mean Absolute Error is called (MAE) and Root Mean Squared Error is called (RMSE)\n",
    "Both MAE and RMSE can range from 0 to âˆž, They are negatively-oriented scores: Lower values are better\n",
    "closer r-squared value is to 1, better is fit\n",
    "An r-squared value of 0 indicates that regression line does not fit data at all while value of 1 indicates a perfect fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816fcd7",
   "metadata": {},
   "source": [
    "```\n",
    "print(\"Linear Regression Model\")\n",
    "print(\"Error Metrics for train set\")\n",
    "evaluator = Metrics()\n",
    "evaluator.evaluate(Linearmodel, newxtrain, newytrain)\n",
    "\n",
    "print(\"Linear Regression Model\")\n",
    "print(\"Error Metrics for test set\")\n",
    "evaluator = Metrics()\n",
    "evaluator.evaluate(Linearmodel, xtest_scaled, ytest)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23a3e1",
   "metadata": {},
   "source": [
    "```\n",
    "print(\"K-Nearest Neighbor(KNN) Model\")\n",
    "print(\"Error Metrics for train set\")\n",
    "evaluator.evaluate(knnmodel, newxtrain, newytrain)\n",
    "\n",
    "print(\"K-Nearest Neighbor(KNN) Model\")\n",
    "print(\"Error Metrics for test set\")\n",
    "evaluator.evaluate(knnmodel, xtest_scaled, ytest)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c41a6",
   "metadata": {},
   "source": [
    "## Model with Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18acc47",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(data[feature_list], data.SalePrice):\n",
    "    print(\"train data index\", train_idx.shape)\n",
    "    print(\"test data index\", test_idx.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e68d4",
   "metadata": {},
   "source": [
    "```\n",
    "LR_eval_test_scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "print(\"Linear Regression Model\")\n",
    "for train_idx, test_idx in kfold.split(data[feature_list], data.SalePrice):\n",
    "    # setting up data\n",
    "    xtrain = data[feature_list].iloc[train_idx]\n",
    "    xtest = data[feature_list].iloc[test_idx]\n",
    "    ytrain = data.SalePrice.iloc[train_idx]\n",
    "    ytest = data.SalePrice.iloc[test_idx]\n",
    "    \n",
    "    # Data Standardization on train set and test set\n",
    "    scaler = StandardScaler()\n",
    "    # fit and transform are both applied on training data\n",
    "    xtrain[feature_list] = scaler.fit_transform(xtrain[feature_list])\n",
    "    # only transform is applied on test data as features used to fit training data is applied in test data to perform transform \n",
    "    xtest[feature_list] = scaler.transform(xtest[feature_list])\n",
    "\n",
    "    # modeling\n",
    "    Linearmodel = LinearRegression()\n",
    "    Linearmodel.fit(xtrain, ytrain)\n",
    "    \n",
    "    # evaluation\n",
    "    print(\"train_report\")\n",
    "    train_report = evaluator.evaluate(model=Linearmodel, features=xtrain, target=ytrain)\n",
    "    print(\"test_report\")\n",
    "    test_report = evaluator.evaluate(model=Linearmodel, features=xtest, target=ytest)\n",
    "    print('=====================================')\n",
    "    LR_eval_test_scores.append(test_report)\n",
    "    \n",
    "LR_eval_test_scores\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b647d5d",
   "metadata": {},
   "source": [
    "```\n",
    "# converting list to numpy array\n",
    "# force-suppress exponential Scientific Notation in Numpy When Creating Array From Nested List\n",
    "np.set_printoptions(suppress=True, formatter={'float_kind':'{:.2f}'.format})\n",
    "LRts = np.array(LR_eval_test_scores)\n",
    "LRts\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13538030",
   "metadata": {},
   "source": [
    "```\n",
    "# order of metrics in array: MAE, MSE, R2 \n",
    "print(\"Max Value: \",LRts.max(axis=0))\n",
    "print(\"Min Value: \",LRts.min(axis=0))\n",
    "print(\"Avg Value: \",LRts.mean(axis=0))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
