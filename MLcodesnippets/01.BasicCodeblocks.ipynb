{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07da13a8",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-missing-value\" data-toc-modified-id=\"Removing-missing-value-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Removing missing value</a></span></li><li><span><a href=\"#preprocessing\" data-toc-modified-id=\"preprocessing-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#column-droping\" data-toc-modified-id=\"column-droping-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>column droping</a></span></li><li><span><a href=\"#droping-rows\" data-toc-modified-id=\"droping-rows-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>droping rows</a></span></li><li><span><a href=\"#changing-all-columns\" data-toc-modified-id=\"changing-all-columns-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>changing all columns</a></span></li><li><span><a href=\"#get_dummies\" data-toc-modified-id=\"get_dummies-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>get_dummies</a></span></li><li><span><a href=\"#Merging-dataframes\" data-toc-modified-id=\"Merging-dataframes-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Merging dataframes</a></span></li><li><span><a href=\"#str.replace()\" data-toc-modified-id=\"str.replace()-1.2.6\"><span class=\"toc-item-num\">1.2.6&nbsp;&nbsp;</span>str.replace()</a></span></li><li><span><a href=\"#str.split()\" data-toc-modified-id=\"str.split()-1.2.7\"><span class=\"toc-item-num\">1.2.7&nbsp;&nbsp;</span>str.split()</a></span></li><li><span><a href=\"#convert-column-type\" data-toc-modified-id=\"convert-column-type-1.2.8\"><span class=\"toc-item-num\">1.2.8&nbsp;&nbsp;</span>convert column type</a></span></li><li><span><a href=\"#Handling-categorical-feature-Using-Map-function\" data-toc-modified-id=\"Handling-categorical-feature-Using-Map-function-1.2.9\"><span class=\"toc-item-num\">1.2.9&nbsp;&nbsp;</span>Handling categorical feature Using Map function</a></span></li><li><span><a href=\"#LabelEncoder\" data-toc-modified-id=\"LabelEncoder-1.2.10\"><span class=\"toc-item-num\">1.2.10&nbsp;&nbsp;</span>LabelEncoder</a></span></li><li><span><a href=\"#index\" data-toc-modified-id=\"index-1.2.11\"><span class=\"toc-item-num\">1.2.11&nbsp;&nbsp;</span>index</a></span></li><li><span><a href=\"#Group-by\" data-toc-modified-id=\"Group-by-1.2.12\"><span class=\"toc-item-num\">1.2.12&nbsp;&nbsp;</span>Group by</a></span></li><li><span><a href=\"#binning\" data-toc-modified-id=\"binning-1.2.13\"><span class=\"toc-item-num\">1.2.13&nbsp;&nbsp;</span>binning</a></span></li><li><span><a href=\"#pivot\" data-toc-modified-id=\"pivot-1.2.14\"><span class=\"toc-item-num\">1.2.14&nbsp;&nbsp;</span>pivot</a></span></li><li><span><a href=\"#P-value\" data-toc-modified-id=\"P-value-1.2.15\"><span class=\"toc-item-num\">1.2.15&nbsp;&nbsp;</span>P-value</a></span></li><li><span><a href=\"#describe()-with-object-type-data\" data-toc-modified-id=\"describe()-with-object-type-data-1.2.16\"><span class=\"toc-item-num\">1.2.16&nbsp;&nbsp;</span>describe() with object type data</a></span></li><li><span><a href=\"#Using-lambda\" data-toc-modified-id=\"Using-lambda-1.2.17\"><span class=\"toc-item-num\">1.2.17&nbsp;&nbsp;</span>Using lambda</a></span></li></ul></li><li><span><a href=\"#train-test-split\" data-toc-modified-id=\"train-test-split-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>train test split</a></span></li></ul></li><li><span><a href=\"#Feature-Selection-Techniques\" data-toc-modified-id=\"Feature-Selection-Techniques-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Feature Selection Techniques</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recursive-Feature-Elimination-(RFE)\" data-toc-modified-id=\"Recursive-Feature-Elimination-(RFE)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Recursive Feature Elimination (RFE)</a></span></li><li><span><a href=\"#Mutual-Info-Regression\" data-toc-modified-id=\"Mutual-Info-Regression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Mutual Info Regression</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Standardization-on-train-set-and-test-set\" data-toc-modified-id=\"Data-Standardization-on-train-set-and-test-set-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Data Standardization on train set and test set</a></span></li><li><span><a href=\"#Outlier-Detection-and-Removal-(optional)\" data-toc-modified-id=\"Outlier-Detection-and-Removal-(optional)-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Outlier Detection and Removal (optional)</a></span></li></ul></li><li><span><a href=\"#Building-Model\" data-toc-modified-id=\"Building-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Building Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression-Model\" data-toc-modified-id=\"Multiple-Linear-Regression-Model-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Multiple Linear Regression Model</a></span></li><li><span><a href=\"#K-Nearest-Neighbor(KNN)-Model\" data-toc-modified-id=\"K-Nearest-Neighbor(KNN)-Model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>K-Nearest Neighbor(KNN) Model</a></span></li></ul></li><li><span><a href=\"#Model-Evaluation-on-train-and-test-dataset\" data-toc-modified-id=\"Model-Evaluation-on-train-and-test-dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Evaluation on train and test dataset</a></span></li><li><span><a href=\"#Model-with-Crossvalidation\" data-toc-modified-id=\"Model-with-Crossvalidation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Model with Crossvalidation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827787dd",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476711e0",
   "metadata": {},
   "source": [
    "### Removing missing value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c09c0922",
   "metadata": {},
   "source": [
    "# removing missing values\n",
    "data.dropna(axis = 0, how ='any',inplace=True) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "334fbf65",
   "metadata": {},
   "source": [
    "# checking missing value\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "773627bc",
   "metadata": {},
   "source": [
    "cat_cols = data.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75125d18",
   "metadata": {},
   "source": [
    "[features for features in df.columns if df[features].isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6cd5a27",
   "metadata": {},
   "source": [
    "# using heatmap to see missing value\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2019c70a",
   "metadata": {},
   "source": [
    "# Replace missing values with mode\n",
    "df['Product_Category_2'] = df['Product_Category_2'].fillna(df['Product_Category_2'].mode()[0])\n",
    "df['Product_Category_2'].isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4bf71ce",
   "metadata": {},
   "source": [
    "# counting missing data in each column in dataset with many columns\n",
    "missing_data = df.isnull()\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    print(column)\n",
    "    print (missing_data[column].value_counts())\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf87b9b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7abb",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbebd5f9",
   "metadata": {},
   "source": [
    "import datetime\n",
    "data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e23003d",
   "metadata": {},
   "source": [
    "from sklearn import preprocessing\n",
    " # label_encoder object knows how to understand word labels\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    " \n",
    "# Encode labels in column Age\n",
    "df['Age']= label_encoder.fit_transform(df['Age'])\n",
    " \n",
    "df['Age'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4f4b08",
   "metadata": {},
   "source": [
    "#### column droping"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27e41d57",
   "metadata": {},
   "source": [
    "data = data.drop(\"datetime\", axis=1)\n",
    "data = data.drop([\"casual\",\"registered\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e16395",
   "metadata": {},
   "source": [
    "#### droping rows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a4f5a87",
   "metadata": {},
   "source": [
    "# droping all row with value ? \n",
    "df = df[(df != '?').all(axis=1)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d29b3f",
   "metadata": {},
   "source": [
    "#### changing all columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52353d67",
   "metadata": {},
   "source": [
    "# changing column names\n",
    "df.columns = ['SL', 'SW', 'PL', 'PW', 'species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20589b0",
   "metadata": {},
   "source": [
    "####  get_dummies\n",
    "method of Pandas is another way to create one-hot encoded features, creating dummy variable for all labels for all categorical column"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35b20ebe",
   "metadata": {},
   "source": [
    "# creating dummy variable for all labels for all categorical column\n",
    "df = pd.get_dummies(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18776aed",
   "metadata": {},
   "source": [
    "# drop_first=True drops first categorical value\n",
    "df_city = pd.get_dummies(df['City_Category'],drop_first=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b5ccc2a",
   "metadata": {},
   "source": [
    "final_df = pd.get_dummies(final_df, columns=[\"Airline\", \"Source\", \"Destination\",\"Additional_Info\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483c377",
   "metadata": {},
   "source": [
    "#### Merging dataframes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7aa2d73f",
   "metadata": {},
   "source": [
    "# how='left' works as sql left join and on='Country Code' is column based on two dataframes joining\n",
    "final_df=pd.merge(df,df_country,on='Country Code', how='left')\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b0de589",
   "metadata": {},
   "source": [
    "# Merge both train and test data by row wise for Feature Engineering\n",
    "df = pd.concat([df_train, df_test],axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed58d28b",
   "metadata": {},
   "source": [
    "#### str.replace()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a7cef1f",
   "metadata": {},
   "source": [
    "df['Stay_In_Current_City_Years']=df['Stay_In_Current_City_Years'].str.replace('+','',regex=False)\n",
    "df['Stay_In_Current_City_Years'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d263df6",
   "metadata": {},
   "source": [
    "#### str.split()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7854ec4",
   "metadata": {},
   "source": [
    "final_df['Date']=final_df['Date_of_Journey'].str.split('/').str[0]\n",
    "final_df['Month']=final_df['Date_of_Journey'].str.split('/').str[1]\n",
    "final_df['Year']=final_df['Date_of_Journey'].str.split('/').str[2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d445cc1",
   "metadata": {},
   "source": [
    "final_df['duration_hour']=final_df['Duration'].str.split(' ').str[0].str.split('h').str[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bef1402",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "987a7468",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02b2559",
   "metadata": {},
   "source": [
    "#### convert column type"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2ead029",
   "metadata": {},
   "source": [
    "# convert object into integers\n",
    "df['Stay_In_Current_City_Years'] = df['Stay_In_Current_City_Years'].astype('int64')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd93601",
   "metadata": {},
   "source": [
    "#### Handling categorical feature Using Map function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed6f1b6c",
   "metadata": {},
   "source": [
    "# Handling categorical feature Gender\n",
    "df['Gender']=df['Gender'].map({'M':0,'F':1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d022924c",
   "metadata": {},
   "source": [
    "df['Age'].value_counts().sort_values()\n",
    "\n",
    "l = sorted(df['Age'].unique())\n",
    "df['Age'] = df['Age'].map({k:i+1 for i,k in enumerate(l)})\n",
    "\n",
    "df['Age'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b6ec197",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb7a5cf0",
   "metadata": {},
   "source": [
    "#### LabelEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd936119",
   "metadata": {},
   "source": [
    "# `LabelEncoder` can be used to normalize labels\n",
    "# This transformer should be used to encode target values y and not input X\n",
    "ffrom sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df.species = encoder.fit_transform(df.species)\n",
    "\n",
    "\n",
    "# can see classes after fit or fit_transform of train data\n",
    "labelencoder.classes_\n",
    "\n",
    "# link: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85c6d732",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc5066c",
   "metadata": {},
   "source": [
    "#### index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbb31856",
   "metadata": {},
   "source": [
    "country_names = final_df.Country.value_counts().index\n",
    "country_val=final_df.Country.value_counts().values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1750d62b",
   "metadata": {},
   "source": [
    "# reset index after droping rows\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b174409",
   "metadata": {},
   "source": [
    "#### Group by"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d9262de",
   "metadata": {},
   "source": [
    "ratings=final_df.groupby(['Aggregate rating','Rating color','Rating text']).size().reset_index().rename(columns={0:'Rating Count'})\n",
    "final_df[final_df['Rating color']=='White'].groupby('Country').size().reset_index()\n",
    "final_df.groupby(['Aggregate rating','Country']).size().reset_index().head(5)\n",
    "final_df[['Country','Currency']].groupby(['Country','Currency']).size().reset_index()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "870a36ed",
   "metadata": {},
   "source": [
    "# groupby function to find average \"price\" of each car based on \"body-style\"\n",
    "df[['price','body-style']].groupby(['body-style'],as_index= False).mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc40cb0a",
   "metadata": {},
   "source": [
    "grouped_test2 = df_gptest[['drive-wheels', 'price']].groupby(['drive-wheels'])\n",
    "# obtaining values of method group using method \"get_group\"\n",
    "grouped_test2.get_group('4wd')['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222e7a6",
   "metadata": {},
   "source": [
    "#### binning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d372ec7c",
   "metadata": {},
   "source": [
    "bins = np.linspace(min(df[\"horsepower\"]), max(df[\"horsepower\"]), 4)\n",
    "group_names = ['Low', 'Medium', 'High']\n",
    "df['horsepower-binned'] = pd.cut(df['horsepower'], bins, labels=group_names, include_lowest=True )\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "from matplotlib import pyplot\n",
    "pyplot.bar(group_names, df[\"horsepower-binned\"].value_counts())\n",
    "\n",
    "# set x/y labels and plot title\n",
    "plt.pyplot.xlabel(\"horsepower\")\n",
    "plt.pyplot.ylabel(\"count\")\n",
    "plt.pyplot.title(\"horsepower bins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d5724",
   "metadata": {},
   "source": [
    "#### pivot"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fa3075b",
   "metadata": {},
   "source": [
    "# grouped data is much easier to visualize when it is made into a pivot table, A pivot table is like an Excel spreadsheet with one variable along column\n",
    "# and another along row, can convert dataframe to a pivot table using method \"pivot\" to create a pivot table from groups\n",
    "df_gptest = df[['drive-wheels','body-style','price']]\n",
    "grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()\n",
    "grouped_pivot = grouped_test1.pivot(index='drive-wheels', columns='body-style')\n",
    "grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0\n",
    "grouped_pivot\n",
    "\n",
    "#use the grouped results\n",
    "plt.pcolor(grouped_pivot, cmap='RdBu')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ccd8ee",
   "metadata": {},
   "source": [
    "#### P-value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8f1ce09",
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "pearson_coef, p_value = stats.pearsonr(df['wheel-base'], df['price'])\n",
    "print(\"The Pearson Correlation Coefficient is\", pearson_coef, \" with a P-value of P =\", p_value)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5d5a3",
   "metadata": {},
   "source": [
    "#### describe() with object type data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b21eef43",
   "metadata": {},
   "source": [
    "df.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f013282",
   "metadata": {},
   "source": [
    "#### Using lambda"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2cda7fec",
   "metadata": {},
   "source": [
    "df[\"Date\"]=df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[0])\n",
    "df[\"Month\"]=df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[1])\n",
    "df[\"Year\"]=df['Date_of_Journey'].apply(lambda x:x.split(\"/\")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6723f1",
   "metadata": {},
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4517123a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data.drop(columns=['SalePrice']), data['SalePrice'], test_size=0.2, random_state=33)\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e26c2c27",
   "metadata": {},
   "source": [
    "# split data\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X,y,random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482a73d",
   "metadata": {},
   "source": [
    "## Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485bb67",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1de2de2",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "rfe = RFE(estimator=DecisionTreeRegressor(), n_features_to_select=5)\n",
    "rfe.fit(xtrain, ytrain)\n",
    "\n",
    "# zip() function returns a zip object which is an iterator of tuples where first item in each passed iterator is paired together \n",
    "# and then second item in each passed iterator are paired together etc\n",
    "# If passed iterators have different lengths, iterator with least items decides length of new iterator\n",
    "feature_list=[]\n",
    "for i, col in zip(range(xtrain.shape[1]), xtrain.columns):\n",
    "    print(i)\n",
    "    print(f\"{col} selected={rfe.support_[i]} rank={rfe.ranking_[i]}\")\n",
    "    if rfe.ranking_[i] == 1:\n",
    "        feature_list.append(col)\n",
    "feature_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c29107",
   "metadata": {},
   "source": [
    "### Mutual Info Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6667d65e",
   "metadata": {},
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "scores = mutual_info_regression(xtrain[feature_list], ytrain, random_state=33)\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.index = xtrain[feature_list].columns\n",
    "scores.sort_values(by=0, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf4ca81",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4913fe",
   "metadata": {},
   "source": [
    "### Data Standardization on train set and test set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94ec2f7d",
   "metadata": {},
   "source": [
    "print(xtrain[feature_list].shape)\n",
    "print(xtest[feature_list].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afeebf46",
   "metadata": {},
   "source": [
    "# Data Standardization on training and test data\n",
    "xtrain_scaled = xtrain[feature_list].copy()\n",
    "print(xtrain_scaled.shape)\n",
    "xtest_scaled = xtest[feature_list].copy()\n",
    "print(xtest_scaled.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e8421e5",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "scaler = StandardScaler()\n",
    "# fit and transform are both applied on training data\n",
    "xtrain_scaled[feature_list] = scaler.fit_transform(xtrain_scaled[feature_list])\n",
    "# only transform is applied on test data as features used to fit training data is applied in test data to perform transform \n",
    "xtest_scaled[feature_list] = scaler.transform(xtest_scaled[feature_list])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77e6da83",
   "metadata": {},
   "source": [
    "sns.pairplot(xtrain_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359bc8c5",
   "metadata": {},
   "source": [
    "### Outlier Detection and Removal (optional)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6dfebb1",
   "metadata": {},
   "source": [
    "newxtrain = xtrain_scaled.copy()\n",
    "newxtrain.shape\n",
    "newytrain = ytrain.copy()\n",
    "newytrain.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aec9ffb8",
   "metadata": {},
   "source": [
    "# orginal function\n",
    "class OutlierTreatment:\n",
    "    \n",
    "    def __init__(self, dff):\n",
    "        self.dff = dff\n",
    "        \n",
    "    def getInfo(self):\n",
    "        return (self.dff.shape)\n",
    "    \n",
    "    def outlier(self):\n",
    "        Q1 = self.dff.quantile(0.25)\n",
    "        Q3 = self.dff.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5*IQR\n",
    "        upper_limit = Q3 + 1.5*IQR\n",
    "        return lower_limit, upper_limit\n",
    "        \n",
    "    def countoutlier(self, dfa):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        Total_outlier = len(dfa[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)])\n",
    "        return Total_outlier\n",
    "    \n",
    "    def cleanoutlier(self, dfa):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        dfx = dfa[(self.dff>self.lower_limit)&(self.dff<self.upper_limit)]\n",
    "        return dfx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa06dc84",
   "metadata": {},
   "source": [
    "# modified function\n",
    "class OutlierTreatment:\n",
    "    \n",
    "    def __init__(self, dff):\n",
    "        self.dff = dff\n",
    "    \n",
    "    def outlier(self):\n",
    "        Q1 = self.dff.quantile(0.25)\n",
    "        Q3 = self.dff.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5*IQR\n",
    "        upper_limit = Q3 + 1.5*IQR\n",
    "        return lower_limit, upper_limit\n",
    "        \n",
    "    def countoutlier(self, dfx):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        Total_outlier = len(dfx[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)])\n",
    "        return Total_outlier\n",
    "    \n",
    "    def cleanoutlier(self, dfx, dfy):\n",
    "        self.lower_limit, self.upper_limit = self.outlier()\n",
    "        outliers = dfx[(self.dff <= self.lower_limit)|(self.dff >= self.upper_limit)]\n",
    "        dfx.drop(outliers.index, inplace=True)\n",
    "        dfy.drop(outliers.index, inplace=True)\n",
    "        return dfx, dfy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2b6a614",
   "metadata": {},
   "source": [
    "# checking total outlier in every feature column\n",
    "for i in newxtrain.columns:\n",
    "        d = OutlierTreatment(newxtrain[i])\n",
    "        d.outlier()\n",
    "        print(i,' ',d.countoutlier(newxtrain))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5456af1",
   "metadata": {},
   "source": [
    "for i in newxtrain.columns:\n",
    "    d = OutlierTreatment(newxtrain[i])\n",
    "    if d.countoutlier(newxtrain) < 5:\n",
    "        d.cleanoutlier(newxtrain, newytrain)\n",
    "print(newxtrain.shape)\n",
    "print(newytrain.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eeb83e00",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.set(style='darkgrid')\n",
    "sns.boxplot(data=newxtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8126070",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b62a039",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28881b46",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "class Metrics:\n",
    "    def evaluate(self, model, features, target):\n",
    "        ypred = model.predict(features)\n",
    "        mae = mean_absolute_error(y_true=target, y_pred=ypred)\n",
    "        mse = mean_squared_error(y_true=target, y_pred=ypred)\n",
    "        r2 = r2_score(y_true=target, y_pred=ypred)*100\n",
    "        print(f\"MAE :: {mae: .4f}\")\n",
    "        print(f\"MSE :: {mse: .4f}\")\n",
    "        print(f\"R2 :: {r2: .4f}\")\n",
    "        return [np.round(mae, 4), np.round(mse, 4), np.round(r2, 4)]\n",
    "evaluator = Metrics()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a81aaf9d",
   "metadata": {},
   "source": [
    "Linearmodel = LinearRegression()\n",
    "Linearmodel.fit(newxtrain, newytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a1476",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor(KNN) Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04482a18",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knnmodel = KNeighborsRegressor(n_neighbors=7)\n",
    "knnmodel.fit(newxtrain, newytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0b014",
   "metadata": {},
   "source": [
    "## Model Evaluation on train and test dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35077531",
   "metadata": {},
   "source": [
    "Mean Absolute Error is called (MAE) and Root Mean Squared Error is called (RMSE)\n",
    "Both MAE and RMSE can range from 0 to ∞, They are negatively-oriented scores: Lower values are better\n",
    "closer r-squared value is to 1, better is fit\n",
    "An r-squared value of 0 indicates that regression line does not fit data at all while value of 1 indicates a perfect fit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e4dfa0d",
   "metadata": {},
   "source": [
    "print(\"Linear Regression Model\")\n",
    "print(\"Error Metrics for train set\")\n",
    "evaluator = Metrics()\n",
    "evaluator.evaluate(Linearmodel, newxtrain, newytrain)\n",
    "\n",
    "print(\"Linear Regression Model\")\n",
    "print(\"Error Metrics for test set\")\n",
    "evaluator = Metrics()\n",
    "evaluator.evaluate(Linearmodel, xtest_scaled, ytest)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55c93fc6",
   "metadata": {},
   "source": [
    "print(\"K-Nearest Neighbor(KNN) Model\")\n",
    "print(\"Error Metrics for train set\")\n",
    "evaluator.evaluate(knnmodel, newxtrain, newytrain)\n",
    "\n",
    "print(\"K-Nearest Neighbor(KNN) Model\")\n",
    "print(\"Error Metrics for test set\")\n",
    "evaluator.evaluate(knnmodel, xtest_scaled, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c41a6",
   "metadata": {},
   "source": [
    "## Model with Crossvalidation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e5e6bb0",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "for train_idx, test_idx in kfold.split(data[feature_list], data.SalePrice):\n",
    "    print(\"train data index\", train_idx.shape)\n",
    "    print(\"test data index\", test_idx.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ac5a31f",
   "metadata": {},
   "source": [
    "LR_eval_test_scores = []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=33)\n",
    "print(\"Linear Regression Model\")\n",
    "for train_idx, test_idx in kfold.split(data[feature_list], data.SalePrice):\n",
    "    # setting up data\n",
    "    xtrain = data[feature_list].iloc[train_idx]\n",
    "    xtest = data[feature_list].iloc[test_idx]\n",
    "    ytrain = data.SalePrice.iloc[train_idx]\n",
    "    ytest = data.SalePrice.iloc[test_idx]\n",
    "    \n",
    "    # Data Standardization on train set and test set\n",
    "    scaler = StandardScaler()\n",
    "    # fit and transform are both applied on training data\n",
    "    xtrain[feature_list] = scaler.fit_transform(xtrain[feature_list])\n",
    "    # only transform is applied on test data as features used to fit training data is applied in test data to perform transform \n",
    "    xtest[feature_list] = scaler.transform(xtest[feature_list])\n",
    "\n",
    "    # modeling\n",
    "    Linearmodel = LinearRegression()\n",
    "    Linearmodel.fit(xtrain, ytrain)\n",
    "    \n",
    "    # evaluation\n",
    "    print(\"train_report\")\n",
    "    train_report = evaluator.evaluate(model=Linearmodel, features=xtrain, target=ytrain)\n",
    "    print(\"test_report\")\n",
    "    test_report = evaluator.evaluate(model=Linearmodel, features=xtest, target=ytest)\n",
    "    print('=====================================')\n",
    "    LR_eval_test_scores.append(test_report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b15dba9",
   "metadata": {},
   "source": [
    "LR_eval_test_scores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a23726b0",
   "metadata": {},
   "source": [
    "# converting list to numpy array\n",
    "# force-suppress exponential Scientific Notation in Numpy When Creating Array From Nested List\n",
    "np.set_printoptions(suppress=True, formatter={'float_kind':'{:.2f}'.format})\n",
    "LRts = np.array(LR_eval_test_scores)\n",
    "LRts"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56f8405d",
   "metadata": {},
   "source": [
    "# order of metrics in array: MAE, MSE, R2 \n",
    "print(\"Max Value: \",LRts.max(axis=0))\n",
    "print(\"Min Value: \",LRts.min(axis=0))\n",
    "print(\"Avg Value: \",LRts.mean(axis=0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f1639d8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d42d7c50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a1410263",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "644e537a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
